# 참고문헌 (References)

1. Fang, Q., Li, H., Luo, X., Ding, L., Luo, H., Rose, T. M., & An, W. (2018). Detecting non-hardhat-use by a deep learning method from far-field surveillance videos. *Automation in Construction,* 85, 1–9. https://doi.org/10.1016/j.autcon.2017.10.009
2. Park, M. W., Elsafty, N., & Zhu, Z. (2020). Hardhat-wearing detection for enhancing on-site safety of construction workers. *Journal of Construction Engineering and Management,* 146(2), 04019113. https://doi.org/10.1061/(ASCE)CO.1943-7862.0001742
3. Liu, L., Guo, Z., Liu, Z., Zhang, Y., Cai, R., Hu, X., Yang, R., & Wang, G. (2024). Multi-Task Intelligent Monitoring of Construction Safety Based on Computer Vision. *Buildings,* 14(8), 2429. https://doi.org/10.3390/buildings14082429
4. 이강호. (2022). 비계 구조물 가속도 기반 딥러닝을 활용한 추락 관련 행동 모니터링. 한양대학교 대학원 석사학위논문.
5. He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2016),* 770–778.
6. Jocher, G., Chaurasia, A., & Qiu, J. (2023). Ultralytics YOLOv8. https://github.com/ultralytics/ultralytics
7. Tan, J., Wang, C., Li, B., Li, Q., Ouyang, W., Yin, C., & Yan, J. (2020). Equalization Loss for Long-Tailed Object Recognition. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020),* 11662–11671.
8. Ren, J., Yu, C., Sheng, S., Ma, X., Zhao, H., Yi, S., & Li, H. (2021). Balanced Meta-Softmax for Long-Tailed Visual Recognition. In *Advances in Neural Information Processing Systems (NeurIPS 2021),* 4175–4186.
9. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., et al. (2021). Learning Transferable Visual Models from Natural Language Supervision. In *Proceedings of the International Conference on Machine Learning (ICML 2021),* 8748–8763.
10. Snell, J., Swersky, K., & Zemel, R. (2017). Prototypical Networks for Few-Shot Learning. In *Advances in Neural Information Processing Systems (NeurIPS 2017),* 30, 4077–4087.
11. Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P. (2017). Focal Loss for Dense Object Detection. In *Proceedings of the IEEE International Conference on Computer Vision (ICCV 2017),* 2980–2988.
12. Cao, K., Wei, C., Gaidon, A., Arechiga, N., & Ma, T. (2019). Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss. In *Advances in Neural Information Processing Systems (NeurIPS 2019),* 1567–1578.
13. Delhi, V. S. K., Ansari, F., Shehab, E., & Alshawi, M. (2020). Detection of Personal Protective Equipment (PPE) compliance in construction sites. *Frontiers in Built Environment,* 6, 136. https://doi.org/10.3389/fbuil.2020.00136
14. Islam, M. S., Shaqib, S. M., Ramit, S., Akter, S., Sattar, A., & Noori, S. R. H. (2024). A Deep Learning Approach to Detect Complete Safety Equipment for Construction Workers Based on YOLOv7. *arXiv preprint arXiv:2406.07707.*
15. Wang, X., & El-Gohary, N. (2025). Few-Shot Object Detection and Attribute Recognition from Construction Site Images for Improved Field Compliance. *Construction Safety Journal.* (Preprint).
16. Vukicevic, A. M., Petrovic, M., Milosevic, P., Peulic, A., Jovanovic, K., & Novakovic, A. (2024). A systematic review of computer vision-based personal protective equipment compliance in industry practice: Advancements, challenges and future directions. *Artificial Intelligence Review,* 57, 319. https://doi.org/10.1007/s10462-024-10978-x
17. Zhang, H., Li, Y., Xu, J., & Gao, Z. (2024). Long-tail distribution learning in visual recognition: A survey. *Pattern Recognition,* 141, 109101. https://doi.org/10.1016/j.patcog.2024.109101
18. Li, Y., Wang, T., Kang, B., Tang, S., Li, J., & Feng, J. (2020). Overcoming classifier imbalance for long-tail object detection with Balanced Group Softmax. *arXiv preprint arXiv:2006.10408.*
19. Wu, Z., & Xiao, Z. (2024). Few-Shot Learning based on Deep Learning: A Survey. *Mathematical Biosciences and Engineering,* 21(1), 679–711. https://doi.org/10.3934/mbe.2024029
20. Ferdaus, M. M., Niles, K. N., Tom, J., & Abdelguerfi, M. (2025). Few-Shot Learning in Video and 3D Object Detection: A Survey. *ACM Computing Surveys.* https://arxiv.org/html/2507.17079v1
21. Jia, C., Yang, Y., Xia, Y., Chen, Y. T., Parekh, Z., Pham, H., et al. (2021). Scaling Up Visual and Vision-Language Representation Learning with Noisy Text Supervision. In *Proceedings of the International Conference on Machine Learning (ICML 2021),* 4904–4916.
22. Yuan, L., Chen, D., Chen, Y. L., Codella, N., Dai, X., Gao, J., et al. (2021). Florence: A New Foundation Model for Computer Vision. *arXiv preprint arXiv:2111.11432.*
23. Bansal, A., Sikka, K., Sharma, G., Chellappa, R., & Divakaran, A. (2018). Zero-Shot Object Detection. *arXiv preprint arXiv:1804.04340.*
24. Gupta, A., Narayan, S., & Bhowmick, S. (2022). CLIP for Domain-Adaptive Zero-Shot Object Detection. *IEEE Access,* 10, 121045–121058.
25. Vinyals, O., Blundell, C., Lillicrap, T., & Wierstra, D. (2016). Matching Networks for One-Shot Learning. In *Advances in Neural Information Processing Systems (NeurIPS 2016),* 29, 3630–3638.
26. He, K., Zhang, X., Ren, S., & Sun, J. (2015). Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. *IEEE Transactions on Pattern Analysis and Machine Intelligence,* 37(9), 1904–1916.
27. Finn, C., Abbeel, P., & Levine, S. (2017). Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In *Proceedings of the International Conference on Machine Learning (ICML 2017),* 1126–1135.

## 추가 참고 자료

- AI Hub. (2022). 공사현장 안전장비 인식 이미지 데이터셋. https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=163
- Jung, Y. G., Park, J., Yoon, J., Peng, K.-C., Kim, W., Beng, J., & Teoh, A. (2025). TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly Detection. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025).* https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_TailedCore_Few-Shot_Sampling_for_Unsupervised_Long-Tail_Noisy_Anomaly_Detection_CVPR_2025_paper.pdf
- Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., & Hospedales, T. M. (2018). Learning to Compare: Relation Network for Few-Shot Learning. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2018),* 1199–1208.
- Yan, X., Chen, Z., Xu, A., Wang, X., Liang, X., & Lin, L. (2019). Meta R-CNN: Towards General Solver for Instance-Level Low-Shot Learning. In *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV 2019),* 9577–9586.
- Fan, Q., Zhuo, W., Tang, C. K., & Tai, Y. W. (2020). Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020),* 4013–4022.
- Qiao, L., Zhao, Y., Li, Z., Qiu, X., Wu, J., & Zhang, C. (2021). DeFRCN: Decoupled Faster R-CNN for Few-Shot Object Detection. In *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV 2021),* 8681–8690.
