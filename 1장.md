# 제 1장 서론

## 1.1 연구 배경

건설 산업은 국가 기반시설의 확충과 경제 성장의 핵심 동력으로 기능해왔다. 그러나 이 산업은 노동집약적이며, 다양한 장비·작업자·환경이 복합적으로 상호작용하는 특성상, 사고 발생 가능성이 매우 높다. 국제노동기구(ILO)의 최근 보고서에 따르면, 전 세계 산업재해 사망자의 약 20%가 건설현장에서 발생하며, 이는 제조업이나 운송업보다도 높은 수치이다. 국내 산업안전보건공단(KOSHA, 2023)에 따르면, 2022년 한 해 동안 건설업 사망자는 전체 산업재해 사망자의 48.3%를 차지하였다.

이처럼 건설현장은 고위험 산업군으로 분류되며, 그 주요 원인은 추락, 낙하, 장비 충돌, 감전, 매몰 등의 반복적인 사고 유형에 있다. 특히 추락 사고는 전체 사망사고의 35% 이상을 차지하며, 이는 대부분 작업자의 개인 보호장비(PPE: Personal Protective Equipment) 미착용 또는 부적절한 사용에서 비롯된다 [1].

이에 따라 정부와 기업들은 작업자의 안전 확보를 위해 개인 보호장비 착용 의무화, 안전관리 인력 증원, 정기적 교육 등의 조치를 시행하고 있으나, 여전히 **인간 중심의 관리 체계는 실시간성, 일관성, 신뢰성의 한계를 가진다**. 예컨대 관리자가 모든 작업자를 동시에 관찰하고 위반 행위를 즉각적으로 탐지하기는 사실상 불가능하다.

이러한 한계를 극복하기 위해 최근에는 **인공지능(AI) 기반의 지능형 영상 분석(Computer Vision)** 기술을 활용하여, 건설현장 내 안전장비 착용 여부를 자동으로 인식하고, 위험 상황을 조기에 감지하는 연구가 활발히 진행되고 있다 [2,3]. 카메라 영상으로부터 안전모, 안전벨트, 안전화 등의 착용 여부를 탐지하거나, 중장비와의 거리·위치 관계를 분석하여 위험 행위를 인식하는 것이 그 대표적인 예이다.

이러한 **AI 기반 안전 모니터링 시스템**은 크게 세 가지 영역으로 구분된다.

1. **PPE 착용 여부 인식(PPE Compliance Detection)**

   * 안전모, 안전조끼, 안전화, 안전벨트 등의 착용 여부를 영상 기반으로 자동 탐지한다.

2. **위험행동 인식(Activity and Gesture Recognition)**

   * 작업자가 추락 위험 구역으로 진입하거나, 안전줄을 미체결한 상태로 이동하는 등 위험 행동을 실시간으로 감지한다 [4].

3. **작업환경 모니터링(Environmental Hazard Recognition)**

   * 장비 간 간격, 개방 가장자리, 낙하 위험 구역 등의 물리적 위험 요소를 인식하여 즉각적인 경보를 발생시킨다.

이러한 연구들은 건설현장 안전관리의 효율성과 정확성을 획기적으로 향상시킬 수 있지만, **현실적인 데이터 문제와 기술적 제약**으로 인해 실제 상용화 수준에는 아직 이르지 못하고 있다.

## 1.2 데이터 기반 안전장비 인식의 문제점

### (1) 대규모 라벨링 데이터 확보의 한계

딥러닝 기반 객체 탐지(Object Detection) 기술은 높은 정확도를 달성하기 위해 대규모의 라벨링 데이터를 필요로 한다.
예를 들어, YOLOv8, Faster R-CNN 등과 같은 대표적인 탐지 모델들은 클래스당 수천 개 이상의 학습 샘플을 요구한다 [5,6].
그러나 실제 건설현장에서는 다양한 각도, 조명, 장비 종류, 작업자 복장, 계절적 변화 등으로 인해 데이터의 일관성을 확보하기 어렵다.

AI Hub(2022)에서 제공하는 “공사현장 안전장비 인식 데이터셋”은 200만 장 이상의 이미지와 9백만 개의 바운딩 박스를 포함하지만,
이 데이터를 구축하는 과정은 엄청난 비용과 시간을 필요로 했다.
라벨링 전문가가 한 장의 이미지를 완전하게 라벨링하는 데 평균 40초가 소요된다고 가정하면, 전체 데이터셋 구축에는 약 22,000시간(2.5년)의 인력이 투입되어야 한다.
이러한 라벨링 비용은 중소규모 건설 기업에게는 현실적으로 감당하기 어렵다.

### (2) 클래스 불균형 문제

AI Hub의 건설 안전 데이터셋 분석 결과, Head–Torso–Tail 구조의 명확한 롱테일(long-tail) 분포가 확인되었다.

| 구분    | 클래스 수 | 클래스당 인스턴스 수   | 전체 비율 | 주요 클래스                |
| ----- | ----- | ------------- | ----- | --------------------- |
| Head  | 10    | 10,000~80,000 | 약 65% | 작업자, 안전모, 굴삭기         |
| Torso | 25    | 1,000~10,000  | 약 30% | 안전벨트, 비계, 콘크리트 믹서     |
| Tail  | 10    | 50~1,000      | 약 5%  | 안전고리, 환기장치, 타워 크레인 후크 |

이러한 불균형은 모델의 학습에 치명적인 영향을 미친다.
대표적인 객체 탐지 모델인 YOLOv8의 경우, Head 클래스에서는 90% 이상의 정확도를 보이지만 Tail 클래스에서는 40% 미만으로 급감한다.
이는 모델이 빈도가 높은 클래스에 과적합(overfitting)되며, 드물게 등장하는 희소 클래스는 제대로 학습하지 못하기 때문이다 [7,8].

결국 “희소 장비일수록 더 인식하기 어렵다”는 역설적인 상황이 발생하며, 이는 실제 안전사고 예방의 실효성을 떨어뜨린다.

### (3) 새로운 장비 및 규정 변화에 대한 적응 한계

건설 산업은 기술 발전과 안전 규정 강화로 인해 지속적으로 새로운 장비가 등장한다.
예를 들어, 2023년 이후 도입된 자동 추락방지 하네스나 고소작업용 보조 로봇 등은 기존 데이터셋에 존재하지 않는다.
따라서 기존의 완전 지도학습 모델은 이러한 새로운 클래스에 대응하지 못한다.
모델을 재학습하기 위해서는 새로운 라벨링 데이터가 필요하며, 이는 다시 막대한 비용과 시간을 요구한다.

요컨대, **대규모 데이터에 의존하는 기존 지도학습 방식은 데이터 갱신과 유지보수 측면에서 비효율적**이다.
이에 따라, **적은 샘플로도 빠르게 학습하고 일반화할 수 있는 학습 패러다임**이 필요하다.

## 1.3 연구 동향 및 기술적 접근

기존의 건설 안전 인식 연구들은 크게 세 가지 방향으로 분류된다.

1. **전통적 컴퓨터 비전 기반 접근법**

   * 초기 연구는 HOG, SIFT, Haar-like Feature 등의 수작업 특징(hand-crafted feature)을 활용하여 안전모 탐지나 작업자 식별을 수행하였다 [1].
   * 그러나 조명 변화나 배경 복잡도에 민감하여 실제 현장 적용이 제한적이었다.

2. **딥러닝 기반 객체 탐지 접근법**

   * CNN 기반 탐지 모델(YOLO, Faster R-CNN 등)을 활용하여 안전장비를 탐지하는 연구들이 등장하였다 [2].
   * 이러한 방법은 높은 정확도를 보이나, 라벨링 데이터가 풍부한 head 클래스에만 유효하며 tail 클래스에서는 탐지 성능이 급격히 하락한다.

3. **불균형 데이터 보정 기반 접근법**

   * Focal Loss [11], LDAM Loss [12], Equalization Loss [7], Balanced Meta-Softmax [8] 등의 손실 함수 기반 연구가 활발히 진행되었다.
   * 그러나 이들 연구 역시 클래스당 최소 100개 이상의 샘플을 필요로 하며, 10개 미만의 극소 데이터 환경에서는 일반화 성능이 제한적이다.

이에 따라 최근 주목받고 있는 기술이 **Few-Shot Learning(FSL)** 과 **Zero-Shot Learning(ZSL)** 이다.

**Zero-Shot Learning**은 모델이 학습 과정에서 본 적 없는 클래스에 대해, 의미론적 관계(예: 텍스트 설명)를 기반으로 분류를 수행하는 방식이다 [9].
예를 들어, CLIP 모델은 “건설현장의 노란색 안전모”와 같은 자연어 설명을 통해 학습 없이도 해당 객체를 인식할 수 있다.

반면, **Few-Shot Learning**은 클래스당 소수(K개)의 샘플만으로도 학습이 가능한 메타 학습(Meta-learning) 기반 방법이다 [10].
특히 Prototypical Networks는 클래스당 대표 벡터(prototype)를 형성하여 새로운 클래스에 빠르게 적응할 수 있는 장점을 가진다.

따라서, 본 연구는 이러한 두 접근법을 결합하여 **“제로샷-퓨샷 하이브리드 학습 프레임워크”**를 제안한다.

## 1.4 연구 목적

본 연구의 목적은 건설 안전장비 인식에서 발생하는 **데이터 불균형과 비용 문제를 최소화하면서, 희소 클래스의 인식 성능을 극대화하는 것**이다.
이를 위해 다음 세부 목표를 설정하였다.

1. **비전-언어 기반 제로샷 인식 모델 개발**

   * CLIP을 활용하여 안전장비의 텍스트 설명만으로 인식 가능한 모델을 구축한다.

2. **Prototypical Networks 기반 퓨샷 학습 설계**

   * 클래스당 5개~10개의 샘플로도 학습 가능한 메타 학습 기반 모델을 개발한다.

3. **비용 효율 분석**

   * 완전 지도학습 대비 라벨링 비용 절감율과 성능 향상 효과를 정량적으로 평가한다.

4. **하이브리드 프레임워크 구현**

   * CLIP의 의미론적 분류 능력과 퓨샷 네트워크의 시각적 세밀성을 결합하여, 실제 건설 데이터에 적합한 통합 모델을 제시한다.

## 1.5 연구의 차별성

기존 연구와 비교할 때, 본 연구의 차별점은 다음과 같다.

* **도메인 적합성**: 건설 안전이라는 특수한 환경을 대상으로, 실제 산업 데이터셋(AI Hub)을 활용한 실증적 평가 수행.
* **데이터 효율성**: 라벨링 샘플을 극단적으로 줄인 상태에서도 높은 탐지 성능을 달성.
* **모델 통합성**: 제로샷(CLIP)과 퓨샷(Prototypical Networks)을 결합한 하이브리드 구조로 일반화 성능 극대화.
* **실용성**: 새로운 장비 도입 시 모델 전체 재학습 없이 빠른 추가 학습 가능.

## 1.6 기대효과 및 학문적 의의

본 연구는 다음과 같은 기대효과를 가진다.

1. **산업적 효과**

   * 건설현장의 안전 모니터링 자동화 수준을 향상시켜, 관리 인력의 부담을 경감.
   * 새로운 장비나 규정이 도입될 때 빠른 모델 업데이트 가능.
   * 라벨링 비용 95% 이상 절감 및 배포 효율성 향상.

2. **학문적 기여**

   * 건설 도메인에 제로샷 및 퓨샷 학습을 적용한 최초의 실증적 연구.
   * 롱테일 데이터 구조에서의 메타 학습 효율성 및 일반화 가능성 검증.
   * Vision-Language 모델(CLIP)의 도메인 적응 가능성을 제시.

3. **사회적 가치**

   * 건설 현장의 안전사고 예방 및 산업재해 감소에 기여.
   * 중소규모 현장의 AI 도입 장벽 완화로 기술 보급 촉진.

## 1.7 논문 구성

본 논문은 다음과 같이 구성된다.

* **제 1장**에서는 연구의 배경, 필요성, 문제 정의, 목적 및 의의를 서술하였다.
* **제 2장**에서는 건설 안전 인식, 롱테일 인식, 퓨샷 및 제로샷 학습 관련 기존 연구를 체계적으로 고찰한다.
* **제 3장**에서는 제안하는 하이브리드 학습 프레임워크(CLIP + ProtoNet)의 구조와 학습 절차를 기술한다.
* **제 4장**에서는 AI Hub 데이터셋을 기반으로 수행한 실험 결과를 제시하고 성능을 비교한다.
* **제 5장**에서는 결과 해석, 비용 분석, 실무 적용 방안을 논의한다.
* **제 6장**에서는 결론과 향후 연구 방향을 제시한다.

