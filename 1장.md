
# 제1장 서론

### 1.1 연구 배경

건설 산업은 국가 경제 발전에 필수적인 기간 산업이지만, 동시에 높은 재해율과 사망률을 수반하는 고위험 산업으로 알려져 있다. 국제노동기구(ILO) 및 각국 산업재해 통계에 따르면, 전체 산업재해 사망사고 중 건설 분야가 차지하는 비율은 약 20% 내외에 이르며, 그 주요 원인은 추락, 충돌, 장비 관련 사고 등이다. 특히 고소 작업 환경과 중장비가 혼재된 공사 현장의 특성상, 개인 보호장비(Personal Protective Equipment, PPE)의 착용 여부와 안전장비의 적절한 사용은 사고 예방을 위한 필수 전제 조건이다.

이에 따라, 안전모·안전벨트·안전화와 같은 PPE 착용 여부 및 안전난간·추락방지장치·안전고리 등의 설치·사용 상태를 자동으로 모니터링하려는 시도가 활발히 이루어지고 있다. 근래에는 CCTV 및 공정 카메라로부터 취득한 영상 데이터를 기반으로, 딥러닝 기반 객체 탐지 및 행동 인식 기술을 적용하여 다음과 같은 작업을 수행하는 연구가 다수 보고되고 있다.

* 안전모, 안전벨트, 안전화 등 PPE 착용 여부 자동 판별
* 개방된 가장자리·고소 작업대 등 고위험 구역 근접 여부 탐지
* 안전고리, 난간, 추락방지 시스템 등의 설치 여부 및 사용 상태 점검

Fang 등[1], Park 등[2]은 딥러닝 기반 객체 탐지 모델을 활용하여 원거리 감시 영상에서도 안전모 착용 여부를 실시간으로 탐지할 수 있음을 보였으며, 이강호[3]는 비계 구조물에 부착된 가속도 센서를 이용하여 추락 관련 행동을 모니터링함으로써 건설 현장의 안전 상태를 정량적으로 평가하고자 하였다. 이러한 연구들은 건설 안전 모니터링 분야에서 딥러닝 기반 접근법의 가능성을 입증하였으나, 대부분 충분한 수의 라벨링 데이터가 확보된 제한된 클래스에 초점을 맞추고 있다는 공통된 한계를 가진다.

실제 건설 현장을 반영한 대규모 영상 데이터셋은 일반적으로 **롱테일(long-tail)** 분포를 보인다. 안전모, 작업자(사람), 굴삭기와 같이 대부분의 현장에서 자주 등장하는 클래스는 수십만 개 이상의 인스턴스를 가지는 반면, 특수 작업에 사용되는 안전고리, 특정 유형의 추락방지 시스템, 밀폐공간 환기장치 등은 등장 빈도가 매우 낮아 수십 개에서 수백 개 수준의 인스턴스만 존재하는 경우가 많다. 이와 같은 클래스 불균형은 기존 완전 지도학습(fully supervised learning) 기반 객체 탐지 모델의 성능을 크게 저해하는 요인으로 작용한다.

특히, 최근 AI Hub에서 제공하는 **공사현장 안전장비 인식 이미지 데이터셋[18]**은 2백만 장 이상의 이미지와 45개 이상의 세분화된 클래스, 약 9백만 개의 바운딩 박스를 포함하는 대규모 데이터셋으로, 실제 건설 현장 환경을 잘 반영하고 있다는 장점이 있다. 그러나 예비 분석 결과, 상위 몇 개의 클래스에 인스턴스가 편중된 전형적인 롱테일 분포를 보이며, 다수의 희소 클래스는 학습에 충분한 양의 라벨링 데이터가 존재하지 않는다는 문제가 확인되었다. 이와 같은 환경에서 전통적인 지도학습 접근법은 다음과 같은 한계를 가진다.

1. **과도한 데이터 의존성**: 클래스당 수천 개 이상의 라벨링 샘플을 필요로 하여, 데이터 수집 및 라벨링에 막대한 비용과 시간이 소요된다.
2. **클래스 불균형에 취약**: 학습 과정에서 head 클래스에 대한 성능은 매우 높게 유지되는 반면, tail 클래스에서는 심각한 성능 저하가 발생하여 실제 안전 모니터링 시스템의 신뢰성을 떨어뜨린다.
3. **새로운 장비 유형에 대한 적응 부족**: 기존에 존재하지 않던 새로운 안전장비 또는 규격이 도입될 경우, 이를 인식하기 위해서는 다시 대규모 데이터 수집과 재학습 과정이 필요하다.

따라서, 롱테일 분포를 갖는 건설 안전 데이터셋 환경에서 **최소한의 라벨링 데이터만으로도 희소 안전장비 클래스를 효과적으로 인식할 수 있는 새로운 학습 패러다임**이 요구된다. 최근 다양한 분야에서 주목받고 있는 제로샷(zero-shot) 및 퓨샷(few-shot) 학습은 이러한 요구를 충족할 수 있는 유망한 방법으로 평가받고 있다. 본 연구는 이러한 관점에서, 건설 안전 장비 인식 문제에 제로샷 및 퓨샷 학습을 적용하고 그 실용 가능성을 체계적으로 검증하고자 한다.

### 1.2 연구 목적

본 연구의 궁극적인 목적은, **롱테일 분포를 갖는 건설 안전장비 데이터셋에서 희소 클래스에 대한 인식 성능을 향상시키면서, 동시에 라벨링 비용을 크게 절감할 수 있는 학습 프레임워크를 제안하고 검증하는 것**이다. 이를 위하여 AI Hub 공사현장 안전장비 인식 데이터셋을 대상으로, 제로샷 및 퓨샷 학습 기법을 통합한 2단계 인식 프레임워크를 설계하고, 기존 완전 지도학습 기반 객체 탐지 방법과 정량적으로 비교·분석한다.

보다 구체적으로, 본 연구는 다음과 같은 세부 목적을 가진다.

1. **비전-언어 모델을 활용한 제로샷 인식 가능성 평가**
   대규모 이미지-텍스트 쌍으로 사전학습된 CLIP[11] 모델을 활용하여, 건설 안전장비에 대한 자연어 설명과 프롬프트 템플릿을 설계하고, 별도의 태스크별 파인튜닝 없이 희소 안전장비 클래스에 대한 제로샷 인식 성능을 정량적으로 평가한다.

2. **퓨샷 학습 기반 희소 클래스 인식 성능 향상**
   Prototypical Networks[4]와 같은 메트릭 학습 기반 퓨샷 학습 기법을 적용하여, 클래스당 5개 또는 10개 수준의 극히 적은 라벨링 샘플만으로도 tail 클래스에서 기존 완전 지도학습 방법과 경쟁 가능한 수준의 성능을 달성할 수 있는지를 검증한다.

3. **롱테일 구조를 고려한 성능 및 비용-효과 분석**
   head/torso/tail 클래스 그룹별로 성능을 세분화하여 분석하고, 라벨링 단위 시간당 성능 향상량을 비교함으로써, 제로샷·퓨샷 학습이 실제 건설 안전 모니터링 시스템에 적용될 때의 비용-효과성을 평가한다.

이러한 목적을 통해, 본 연구는 건설 안전 장비 인식 문제에서 **대규모 균형 데이터셋에 대한 의존도를 줄이고, 새로운 장비 유형 및 희귀 안전 시나리오에 신속하게 적응할 수 있는 인공지능 기반 안전 모니터링 시스템의 설계 방향**을 제시하고자 한다.


### 1.3 연구 문제

상기 목적을 달성하기 위해, 본 연구는 다음과 같은 구체적인 연구 문제를 설정한다.

* **연구 문제 1 (RQ1)**
  비전-언어 모델(CLIP)을 활용한 제로샷 학습이, 태스크별 추가 학습 없이도 건설 안전장비 인식 태스크에서 의미 있는 수준의 성능을 달성할 수 있는가? 특히, 희소 클래스와 같이 학습용 이미지가 거의 존재하지 않는 장비 유형에 대해서도 일정 수준 이상의 인식 정확도를 보이는가?

* **연구 문제 2 (RQ2)**
  롱테일 분포를 갖는 건설 안전장비 데이터셋에서, tail 클래스를 중심으로 완전 지도학습 방식과 비교할 때, 퓨샷 학습이 유사한 수준의 성능을 달성하기 위해 필요한 최소 라벨링 샘플 수(예: 5-shot, 10-shot, 20-shot)는 어느 정도인가?

* **연구 문제 3 (RQ3)**
  동일한 데이터셋과 하드웨어 환경에서, 제로샷 및 퓨샷 학습 방법과 기존 완전 지도학습 기반 객체 탐지 모델(YOLOv8, Faster R-CNN 등)의 성능을 head/torso/tail 클래스별로 비교할 경우, 라벨링 비용과 인식 성능 간의 트레이드오프는 어떻게 나타나는가? 또한, 제로샷과 퓨샷을 결합한 하이브리드 접근법이 단일 방법 대비 어떤 추가적인 이점을 제공하는가?

위 연구 문제에 대한 답을 도출함으로써, 본 연구는 제로샷 및 퓨샷 학습이 건설 안전장비 인식 문제에서 가지는 이론적·실무적 의미를 동시에 규명하고자 한다.


### 1.4 연구 범위 및 한계

본 연구의 분석 대상과 범위는 다음과 같이 한정한다.

1. **데이터셋 범위**
   사용되는 주요 데이터셋은 AI Hub에서 제공하는 공사현장 안전장비 인식 이미지 데이터셋[18]으로 한정한다. 이 데이터셋은 45개 안전장비 및 관련 객체 클래스를 포함하며, 실제 건설 현장의 CCTV·사진 데이터를 기반으로 구축되었다. 타 도메인(예: 제조, 광업, 의료 영상 등)은 본 연구의 직접적인 실험 범위에서 제외한다.

2. **과업(Task)의 범위**
   본 연구는 주로 **객체 인식(분류)** 성능에 초점을 맞추어 제로샷 및 퓨샷 학습 기법을 평가한다. 객체 탐지(detection) 전체 파이프라인(위치 추정 + 분류)을 모두 퓨샷/제로샷으로 처리하는 문제는 매우 도전적인 과제이며, 본 연구에서는 클래스 인식 성능에 초점을 두고 후속 연구 주제로 남긴다. 다만, 실제 응용을 고려하여, class-agnostic RPN 또는 기존 탐지기를 통해 얻은 후보 영역에 대해 제로샷·퓨샷 분류기를 적용하는 형태로 탐지 문제와의 연계를 논의한다.

3. **모델 및 기법의 범위**
   제로샷 학습 모델로는 CLIP[11]을, 퓨샷 학습 모델로는 Prototypical Networks[4]를 중심으로 실험을 수행한다. 그 외의 다양한 메타 학습 기법(MAML, Meta-RCNN 등)은 비교 대상으로 일부 포함하되, 본 연구의 핵심 제안 모델은 Prototypical Networks 기반 프레임워크에 한정한다.

4. **환경 및 도메인 시프트**
   데이터셋이 반영하는 환경은 국내·외 건설 현장의 일반적인 상황에 국한되며, 극단적인 조명 변화, 특수한 실내 작업장, 비표준 장비가 다수 등장하는 특수 현장은 고려 대상에서 제외된다. 도메인 시프트 문제(예: 다른 국가의 건설 현장, 다른 촬영 장비로 인한 분포 차이)는 본 연구에서 부분적으로 논의하나, 정량적인 실험은 후속 연구로 남긴다.

5. **실시간성 및 시스템 통합**
   본 연구는 모델의 인식 성능 및 데이터 효율성에 초점을 맞추며, 실제 현장 시스템과의 완전한 통합(예: 경고 시스템, UI, 네트워크 지연 등)과 실시간 처리 성능 최적화는 범위 밖으로 설정한다. 다만, 제안 방법의 연산 복잡도와 추론 속도에 대한 기본적인 비교는 수행한다.

이와 같은 범위 설정은, 연구의 초점을 **롱테일 데이터셋에서의 제로샷·퓨샷 학습의 타당성과 효과**를 검증하는 데 두기 위한 것이다. 따라서 본 논문의 결론은 위에서 정의한 범위 내에서 해석될 필요가 있다.


### 1.5 논문의 구성

본 논문의 구성은 다음과 같다.

* **제2장 관련 연구**에서는 건설 안전 모니터링 분야에서의 기존 컴퓨터 비전 및 딥러닝 기반 연구를 정리하고, 롱테일 인식, 퓨샷 학습, 제로샷 학습과 관련된 선행 연구들을 체계적으로 고찰한다. 이를 통해 본 연구가 위치하는 연구적 맥락과 기존 연구의 한계를 정리한다.

* **제3장 제안 방법**에서는 본 논문에서 다루는 문제를 공식적으로 정식화하고, CLIP을 이용한 제로샷 인식, Prototypical Networks 기반 퓨샷 학습, 그리고 두 접근법을 결합한 하이브리드 프레임워크의 세부 구조와 학습 절차를 제시한다.

* **제4장 실험 환경 및 설정**에서는 사용한 데이터셋의 구조와 롱테일 분포 특성을 분석하고, 비교 대상 모델, 학습 및 평가 절차, 하드웨어 환경 등 실험 설정에 대해 상세히 설명한다.

* **제5장 실험 결과**에서는 제로샷·퓨샷·하이브리드 모델과 기존 완전 지도학습 기반 객체 탐지 모델의 성능을 정량적으로 비교하고, head/torso/tail 클래스별 성능 분석, 비용-효과 분석, 분리 연구(ablation study) 결과를 제시한다.

* **제6장 논의**에서는 실험 결과를 바탕으로 건설 안전 도메인에서 퓨샷 학습이 효과적인 이유를 분석하고, 제안 방법의 한계와 실용적 의의를 논의하며, 의료 영상·자율주행·리테일 등 인접 도메인과의 비교를 통해 일반화 가능성을 검토한다.

* **제7장 결론 및 향후 연구**에서는 본 연구의 주요 내용을 요약하고, 학문적·실무적 기여를 정리한 뒤, 퓨샷 객체 탐지, 능동 학습, 지속적 학습 등 후속 연구 방향을 제안한다.


