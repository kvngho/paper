# ì°¸ê³ ë¬¸í—Œ (References)

### ğŸ”¹ ê±´ì„¤ ì•ˆì „ ë° ì˜ìƒ ê¸°ë°˜ ì¸ì‹ ê´€ë ¨

Fang, Q., Li, H., Luo, X., Ding, L., Luo, H., Rose, T. M., & An, W. (2018). Detecting non-hardhat-use by a deep learning method from far-field surveillance videos. *Automation in Construction,* 85, 1â€“9. [https://doi.org/10.1016/j.autcon.2017.10.009](https://doi.org/10.1016/j.autcon.2017.10.009)

Park, M. W., Elsafty, N., & Zhu, Z. (2020). Hardhat-wearing detection for enhancing on-site safety of construction workers. *Journal of Construction Engineering and Management,* 146(2), 04019113. [https://doi.org/10.1061/(ASCE)CO.1943-7862.0001742](https://doi.org/10.1061/%28ASCE%29CO.1943-7862.0001742)

ì´ê°•í˜¸. (2022). ë¹„ê³„ êµ¬ì¡°ë¬¼ ê°€ì†ë„ ê¸°ë°˜ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ì¶”ë½ ê´€ë ¨ í–‰ë™ ëª¨ë‹ˆí„°ë§. í•œì–‘ëŒ€í•™êµ ëŒ€í•™ì› ì„ì‚¬í•™ìœ„ë…¼ë¬¸.

Delhi, V. S. K., Ansari, F., Shehab, E., & Alshawi, M. (2020). Detection of Personal Protective Equipment (PPE) compliance in construction sites. *Frontiers in Built Environment,* 6, 136. [https://doi.org/10.3389/fbuil.2020.00136](https://doi.org/10.3389/fbuil.2020.00136)

Liu, L., Guo, Z., Liu, Z., Zhang, Y., Cai, R., Hu, X., Yang, R., & Wang, G. (2024). Multi-Task Intelligent Monitoring of Construction Safety Based on Computer Vision. *Buildings,* 14(8), 2429. [https://doi.org/10.3390/buildings14082429](https://doi.org/10.3390/buildings14082429)

Vukicevic, A. M., Petrovic, M., Milosevic, P., Peulic, A., Jovanovic, K., & Novakovic, A. (2024). A systematic review of computer vision-based personal protective equipment compliance in industry practice: Advancements, challenges and future directions. *Artificial Intelligence Review,* 57, 319. [https://doi.org/10.1007/s10462-024-10978-x](https://doi.org/10.1007/s10462-024-10978-x)

Islam, M. S., Shaqib, S. M., Ramit, S., Akter, S., Sattar, A., & Noori, S. R. H. (2024). A Deep Learning Approach to Detect Complete Safety Equipment for Construction Workers Based on YOLOv7. *arXiv preprint arXiv:2406.07707.* [https://arxiv.org/abs/2406.07707](https://arxiv.org/abs/2406.07707)

Wang, X., & El-Gohary, N. (2025). Few-Shot Object Detection and Attribute Recognition from Construction Site Images for Improved Field Compliance. *Construction Safety Journal.* (Preprint) [https://experts.illinois.edu/en/publications/few-shot-object-detection-and-attribute-recognition-from-construc](https://experts.illinois.edu/en/publications/few-shot-object-detection-and-attribute-recognition-from-construc)

### ğŸ”¹ ë¡±í…Œì¼ ì¸ì‹ ë° ë¶ˆê· í˜• ë°ì´í„° í•™ìŠµ

Zhang, H., Li, Y., Xu, J., & Gao, Z. (2024). Long-tail distribution learning in visual recognition: A survey. *Pattern Recognition,* 141, 109101. [https://doi.org/10.1016/j.patcog.2024.109101](https://doi.org/10.1016/j.patcog.2024.109101)

Li, Y., Wang, T., Kang, B., Tang, S., Li, J., & Feng, J. (2020). Overcoming classifier imbalance for long-tail object detection with Balanced Group Softmax. *arXiv preprint arXiv:2006.10408.* [https://arxiv.org/abs/2006.10408](https://arxiv.org/abs/2006.10408)

Cao, K., Wei, C., Gaidon, A., Arechiga, N., & Ma, T. (2019). Learning Imbalanced Datasets with Label-Distribution-Aware Margin Loss. In *Advances in Neural Information Processing Systems (NeurIPS 2019),* 1567â€“1578.

Tan, J., Wang, C., Li, B., Li, Q., Ouyang, W., Yin, C., & Yan, J. (2020). Equalization Loss for Long-Tailed Object Recognition. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020),* 11662â€“11671.

Ren, J., Yu, C., Sheng, S., Ma, X., Zhao, H., Yi, S., & Li, H. (2021). Balanced Meta-Softmax for Long-Tailed Visual Recognition. In *Advances in Neural Information Processing Systems (NeurIPS 2021),* 4175â€“4186.

Jung, Y. G., Park, J., Yoon, J., Peng, K.-C., Kim, W., Beng, J., & Teoh, A. (2025). TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly Detection. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2025).* [https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_TailedCore_Few-Shot_Sampling_for_Unsupervised_Long-Tail_Noisy_Anomaly_Detection_CVPR_2025_paper.pdf](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_TailedCore_Few-Shot_Sampling_for_Unsupervised_Long-Tail_Noisy_Anomaly_Detection_CVPR_2025_paper.pdf)

### ğŸ”¹ í“¨ìƒ·(Few-shot) ë° ì œë¡œìƒ·(Zero-shot) í•™ìŠµ

Snell, J., Swersky, K., & Zemel, R. (2017). Prototypical Networks for Few-Shot Learning. In *Advances in Neural Information Processing Systems (NeurIPS 2017),* 30, 4077â€“4087.

Vinyals, O., Blundell, C., Lillicrap, T., & Wierstra, D. (2016). Matching Networks for One-Shot Learning. In *Advances in Neural Information Processing Systems (NeurIPS 2016),* 29, 3630â€“3638.

Sung, F., Yang, Y., Zhang, L., Xiang, T., Torr, P. H., & Hospedales, T. M. (2018). Learning to Compare: Relation Network for Few-Shot Learning. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2018),* 1199â€“1208.

Finn, C., Abbeel, P., & Levine, S. (2017). Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In *Proceedings of the International Conference on Machine Learning (ICML 2017),* 1126â€“1135.

Yan, X., Chen, Z., Xu, A., Wang, X., Liang, X., & Lin, L. (2019). Meta R-CNN: Towards General Solver for Instance-Level Low-Shot Learning. In *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV 2019),* 9577â€“9586.

Fan, Q., Zhuo, W., Tang, C. K., & Tai, Y. W. (2020). Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2020),* 4013â€“4022.

Qiao, L., Zhao, Y., Li, Z., Qiu, X., Wu, J., & Zhang, C. (2021). DeFRCN: Decoupled Faster R-CNN for Few-Shot Object Detection. In *Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV 2021),* 8681â€“8690.

Wu, Z., & Xiao, Z. (2024). Few-Shot Learning based on Deep Learning: A Survey. *Mathematical Biosciences and Engineering,* 21(1), 679-711. [https://doi.org/10.3934/mbe.2024029](https://doi.org/10.3934/mbe.2024029)

Ferdaus, M. M., Niles, K. N., Tom, J., & Abdelguerfi, M. (2025). Few-Shot Learning in Video and 3D Object Detection: A Survey. *ACM Computing Surveys.* [https://arxiv.org/html/2507.17079v1](https://arxiv.org/html/2507.17079v1)

### ğŸ”¹ ë¹„ì „-ì–¸ì–´(Vision-Language) ë° ì œë¡œìƒ· í•™ìŠµ ê´€ë ¨

Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., et al. (2021). Learning Transferable Visual Models from Natural Language Supervision. In *Proceedings of the International Conference on Machine Learning (ICML 2021),* 8748â€“8763.

Jia, C., Yang, Y., Xia, Y., Chen, Y. T., Parekh, Z., Pham, H., et al. (2021). Scaling Up Visual and Vision-Language Representation Learning with Noisy Text Supervision. In *Proceedings of the International Conference on Machine Learning (ICML 2021),* 4904â€“4916.

Yuan, L., Chen, D., Chen, Y. L., Codella, N., Dai, X., Gao, J., et al. (2021). Florence: A New Foundation Model for Computer Vision. *arXiv preprint arXiv:2111.11432.*

### ğŸ”¹ ì¼ë°˜ ë”¥ëŸ¬ë‹ ë° ê°ì²´ íƒì§€ ê¸°ë°˜

Lin, T. Y., Goyal, P., Girshick, R., He, K., & DollÃ¡r, P. (2017). Focal Loss for Dense Object Detection. In *Proceedings of the IEEE International Conference on Computer Vision (ICCV 2017),* 2980â€“2988.

He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition. In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2016),* 770â€“778.

Jocher, G., Chaurasia, A., & Qiu, J. (2023). Ultralytics YOLOv8. [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)

AI Hub. (2022). ê³µì‚¬í˜„ì¥ ì•ˆì „ì¥ë¹„ ì¸ì‹ ì´ë¯¸ì§€ ë°ì´í„°ì…‹. Retrieved from [https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=163](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=163)

